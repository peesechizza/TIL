# Chapter 14. 가상 메모리

## 14-1. 연속 메모리 할당

프로세스에 연속적인 메모리 공간을 할당하는 방식을 **연속 메모리 할당 방식**이라고 한다.

### 스와핑

메모리에서 사용되지 않는 일부 프로세스를 보조기억장치로 내보내고 실행할 프로세스를 메모리로 들여보내는 메모리 관리 기법이다.

이때 프로세스들이 쫓겨나는 보조기억장치의 일부 영역을 `스왑 영역` 이라고 한다.

그리고 현재 실행되지 않는 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것을 `스왑 아웃`, 반대로 스왑 영역에 있던 프로세스가 다시 메모리로 옮겨오는 것을 `스왑 인`이라고 한다.

### 메모리 할당

프로세스는 메모리 내의 빈 공간에 적재되어야 한다. 비어 있는 메모리 공간이 프로세스를 연속적으로 할당하는 방식에는 `최초 적합`, `최적 적합`, `최악 적합`의 세 가지 방식이 있다.

**최초 적합**

운영체제가 메모리 내의 빈 공간을 순서대로 검색하다가 적재할 수 있는 공간을 발견한다면 그 공간에 프로세스를 배치하는 방식이다. 최초 적합 방식은 프로세스가 적재될 수 있는 공간을 발견하는 즉시 메모리를 할당하는 방식이므로 검색을 최소화 할 수 있고, 빠른 할당이 가능하다.

**최적 적합**

운영체제가 빈 공간을 모두 검색해 본 후 프로세스가 적재될 수 있는 공간 중 가장 작은 공간에 프로세스를 배치하는 방식이다.

**최악 적합**

운영체제가 빈 공간을 모두 검색해 본 후, 프로세스가 적재될 수 있는 공간 중 가장 큰 공간에 프로세스를 배치하는 방식이다.

### 외부 단편화

프로세스들이 메모리에 연속적으로 할당되는 환경에서는 프로세스들이 실행되고 종료되기를 반복하며 메모리 사이 사이에 빈 공간들이 생긴다. 그 공간보다 큰 프로세스를 적재하기 어려운 상황을 초래하고, 메모리 낭비로 이어지게 된다. 이러한 현상을 외부 단편화라고 한다.

외부 단편화를 해결할 수 있는 대표적인 방안으로 메모리를 **압축**하는 방법이 있다.

하지만 여러 단점이 있다. 작은 빈 공간들을 하나로 모으는 동안 시스템은 하던 일을 중지해야 하고, 메모리에 있는 내용을 옮기는 작업은 많은 오버헤드를 야기하며, 오버헤드를 최소화하며 압축할 수 있는지에 대한 명확한 방법을 결정하기 어렵다.

## 14-2. 페이징을 통한 가상 메모리 관리

가상메모리는 실행하고자 하는 프로그램을 일부만 메모리에 적재하려 실제 물리 메모리 크기보다 더 큰 프로세스를 실행할 수 있게 하는 기술이다.

### 페이징이란

메모리의 물리 주소 공간을 **프레임** 단위로 자르고, 프로세스의 논리 주소 공간을 **페이지** 단위로 자른 뒤 각 페이지를 프레임에 할당하는 가상 메모리 관리 기법이다.

페이징을 사용하는 시스템에서는 페이지 단위로 스왑 아웃/스왑 인이 일어나는데, 페이지 인, 페이지 아웃이라 한다.

한 프로세스를 실행하기 위해 프로세스 전체가 메모리에 적재될 필요가 없다. 프로세스를 이루는 페이지 중 실행에 필요한 일부 페이지만을 메모리에 적재하고, 당장 실행에 필요하지 않은 페이지들은 보조기억장치에 남겨둘 수 있다.

### 페이지 테이블

프로세스가 메모리에 불연속적으로 배치되면 CPU 입장에서 다음에 실행할 명령어 위치를 찾기 어렵다.

페이징 시스템은 프로세스가 물리 주소에 불연속으로 배치되더라도 논리 주소에는 연속적으로 배치되도록 페이징 테이블을 이용한다

페이지 테이블은 현재 어떤 페이지가 어떤 프레임에 할당되었는지를 페이지 번호를 이용해 알려준다.

프로세스마다 각자의 프로세스 테이블을 가지고 있고 각 프로세스의 페이지 테이블들은 메모리에 적재되어 있다. 그리고 CPU 내의 **페이지 테이블 베이스 레지스터(PTBR)**는 각 프로세스의 페이지 테이블이 적재된 주소를 가리키고 있다.

페이지 테이블을 메모리에 두면 메모리 접근 시간이 두 배로 늘어나기 때문에 이와 같은 문제를 해결하기 위해 CPU 곁에 TLB라는 페이지 테이블의 캐시 메모리를 둔다.

CPU가 발생한 논리 주소에 대한 페이지 번호가 TLB에 있을 경우 TLB 히트라고 한다. 이 경우에는 페이지가 적재된 프레임을 알기 위해 메모리에 접근할 필요가 없다. 하지만 만일 페이지 번호가 TLB에 없을 경우 어쩔 수 없이 페이지가 적재된 프레임을 알기 위해 메모리 내의 페이지 테이블에 접근하는 수 밖에 없는데 이를 TLB 미스라고 한다.

### 내부 단편화

페이징은 외부 단편화 문제를 해결할 수 있지만, 내부 단편화라는 문제를 야기할 수 있다.

내부 단편화는 하나의 페이지 크기보다 작은 크기로 발생한다. 그렇기에 하나의 페이지 크기가 작다면 발생하는 내부 단편화의 크기는 작아질 것으로 기대할 수 있다.

참고로 리눅스를 포함한 일부 운영체제에서는 위와 같이 기본적으로 설정된 페이지 크기보다 더 큰 크기의 페이지도 일부 허용하며 메모리에 유지하는 경우도 있다. 기본적으로 설정된 페이지보다 큰 페이지를 대형 페이지라고 한다.

### 페이지에서의 주소 변환

하나의 페이지 혹은 프레임은 여러 주소를 포괄하고 있기에 특정 주소에 접근하려면 어떤 페이지 혹은 프레임에 접근하고 싶은지, 접근하려는 주소가 그 페이지 혹은 프레임으로부터 얼마나 떨어져있는지 정보가 필요하다.

그렇기에 페이징 시스템에서는 모든 논리 주소가 기본적으로 **페이지 번호**와 **변위**로 이루어져 있다.

### 페이지 테이블 엔트리

페이지 테이블의 각각 행들을 페이지 테이블 엔트리라고 한다.

**유효 비트**

현재 해당 페이지에 접근 가능한지 여부를 알려준다. 페이지 테이블 엔트리에서 프레임 번호 다음으로 중요한 정보이다. 프로세스를 이루는 모든 페이지가 메모리에 있진 않고, 일부 페이지는 보조기억장치에 있는 경우가 많다. 유효 비트는 현재 페이지가 메모리에 적재되어 있는지 아니면 보조기억장치에 있는지를 알려주는 비트이다.

CPU가 유효 비트가 0인 메모리에 적재되어 있지 않은 페이지로 접근하려고 하면 `페이지 폴트`라는 예외가 발생한다.

CPU가 페이지 폴트를 처리하는 과정은 하드웨어 인터럽트를 처리하는 과정과 유사하다.

1. CPU는 기존의 작업 내역을 백업한다.
2. 페이지 폴트 처리 루틴을 처리한다.
3. 페이지 처리 루틴은 원하는 페이지를 메모리로 가져온 뒤 유효 비트를 1로 변경해준다.
4. 페이지 폴트를 처리했다면 이제 CPU는 해당 페이지에 접근할 수 있다.

**보호 비트**

페이지 보호 기능을 위해 존재하는 비트이다. 보호 비트를 통해 해당 페이지가 읽고 쓰기가 모두 가능한 페이지인지(0), 혹은 읽기만 가능한 페이지인지(1)를 나타낼 수 있다.

세 개의 비트로 조금 더 복잡하게 구현할 수 있다. 읽기를 나타내는 r, 쓰기를 나타내는 w, 실행을 나타내는 x의 조합으로 읽기, 쓰기, 실행하기 권한의 조합을 나타낼 수도 있다.

**참조 비트**

CPU가 이 페이지에 접근한 적이 있는지 여부를 나타낸다. 적재 이후 CPU가 읽거나 쓴 페이지는 참조 비트가 1로 세팅되고, 적재 이후 한 번도 읽거나 쓴 적이 없는 페이지는 0으로 유지된다.

**수정 비트**

해당 페이지에 데이터를 쓴 적이 있는지(1) 없는지(0) 수정 여부를 알려준다. 더티 비트라고도 부른다. 수정 비트는 페이지가 메모리에서 사라질 때 보조기억장치에 쓰기 작업을 해야 하는지, 할 필요가 없는지를 판단하기 위해 존재한다.

### 페이징의 이점 - 쓰기 시 복사

외부 단편화 문제를 해결한다는 점 이외에도 페이징에 제공하는 이점 중 대표적인 것이 프로세스 간에 페이지를 공유할 수 있다는 점이다. 대표 적인 예시로 쓰기 시 복사가 있다.

부모 프로세스와 동일한 자식 프로세스가 생성되면 자식 프로세스로 하여금 부모 프로세스와 동일한 프레임을 가리키면서 부모 프로세스의 메모리 공간을 복사하지 않고도 동리한 코드 및 데이터 영역을 가리킬 수 있다. 그런데 프로세스 간에는 자원을 공유하지 않기 때문에 부모 프로세스 혹은 자식 프로세스 둘 중 하나가 페이지에 쓰기 작업을 하면 그 순간 해당 페이지가 별도의 공간으로 복제된다. 각 프로세스는 자신의 고유한 페이지가 할당된 프레임을 가리키는데, 이것이 쓰기 시 복사이다.

### 계층적 페이징

페이지 테이블의 크기가 커지면 프로세스 테이블의 크기도 커지기 때문에 모든 페이지 테이블 엔트리를 메모리에 두는 것은 큰 메모리 낭비기 때문에, 이 낭비를 줄일 수 있는 계층적 페이징이 등장했다.

계층적 페이징은 페이지 테이블을 페이징하여 여러 단계의 페이지를 두는 방식이다. 여러 단계의 페이지를 둔다는 점에서 다단계 페이지 테이블 기법이라고도 부른다. 프로세스의 페이지 테이블을 여러 개의 페이지로 자르고, 바깥쪽에 페이지 테이블을 하나 더 두어 잘린 페이지 테이블의 페이지들을 가리키게 하는 방식이다.

계층적 페이징을 사용하는 경우 CPU가 발생하는 논리 주소도 달라진다. 바깥 페이지 번호에 해당하는 항목은 CPU와 근접한 곳에 위치한 페이지 테이블 엔트리를 가리키고, 안쪽 페이지 번호는 첫 번째 페이지 테이블 바깥에 위치한 두 번째 페이지 테이블, 즉 페이지 테이블의 페이지 번호를 가리킨다.

이러한 논리 주소를 토대로 주소 변환은 바깥 페이지 번호를 통해 페이지 테이블의 페이지를 찾고, 페이지 테이블의 페이지를 통해 프레임 번호를 찾고 변위를 더함으로서 물리 주소를 얻는 방법으로 이루어진다.

## 14-3. 페이지 교체와 프레임 할당

### 요구 페이징

프로세스를 메모리에 적재할 때 처음부터 모든 페이지를 적재하지 않고 필요한 페이지만을 메모리에 적재하는 기법을 요구 페이징이라고 한다.

1. CPU가 특정 페이지에 접근하는 명령어를 실행한다.
2. 해당 페이지가 현재 메모리에 있을 경우(유효비트 1) CPU는 페이지가 적재된 프레임에 접근한다.
3. 해당 페이지가 현재 메모리에 없을 경우(유효비트 0) 페이지 폴트가 발생한다.
4. 페이지 폴트 처리 루틴은 해당 페이지를 메모리로 적재하고 유효 비트를 1로 설정한다.
5. 다시 1번 수행

아무런 페이지도 메모리에 적재하지 않은 채 무작적 실행을 할 경우 프로세스의 첫 명령어를 실행하는 순간부터 페이지 폴트가 계속 발생하게 되고, 실행에 필요한 페이지가 어느 정도 적재된 이후부터는 페이지 폴트 발생 빈도가 떨어지는데, 이를 `순수 요구 페이징 기법`이라고 한다.

요구 페이징 시스템이 안정적으로 작동하려면 페이지 교체, 프레임 할당을 해결해야 한다.

요구 페이징 기법으로 페이지를 적재하다보면 메모리가 가득 차게 되는데, 이때는 당장 실행에 필요한 페이지를 적재하기 위해 메모리에 적재된 페이지를 보조기억장치로 내보내야 한다. 이를 결정하는 방법이 페이지 교체 알고리즘이다.

### 페이지 교체 알고리즘

페이지 교체 알고리즘을 제대로 이해하려면 페이지 폴트 횟수를 알 수 있어야 한다. 페이지 폴트 횟수는 페이지 참조열을 통해 알 수 있다. CPU가 참조하는 페이지들 중 연속된 페이지를 생략한 페이지열을 의미한다.

**FIFO 페이지 교체 알고리즘**

메모리에 가장 먼저 올라온 페이지부터 내쫓는 방식이다.

**2차 기회 페이지 교체 알고리즘**

FIFO 페이지 교체 알고리즘의 부작용을 개선한 변형이다.

가장 오래 머물렀던 페이지를 대상으로 내보낼 페이지를 선별하고, 차이가 있다면 만일 페이지의 참조 비트가 1일 경우, 당장 내쫓지 않고 참조 비트를 0으로 만든 뒤 현재 시간을 적재 시간으로 설정한다. 메모리에 가장 오래 머물렀다고 할지라도 참조 비트가 1이라는 의미는 CPU가 접근한 적이 있다는 의미이므로 한 번의 기회를 더 주는 셈이다.

**최적 페이지 교체 알고리즘**

CPU에 의해 참조되는 횟수(앞으로의 사용 빈도가 가장 낮은 페이지)를 고려하는 페이지 교체 알고리즘이다. 주로 다른 페이지 교체 알고리즘의 이론상 성능을 평가하기 위한 목적으로 사용된다. 최적 페이지 교체 알고리즘을 실행했을 때 발생하는 페이지 폴트 횟수를 페이지 폴트의 하한선으로 간주하고, 최적 페이지 교체 알고리즘에 비해 얼만큼 페이지 폴트 횟수가 발생하느냐를 통해 페이지 교체 알고리즘을 평가하기 위해 사용된다.

**LRU 페이지 교체 알고리즘**

오랫동안 사용되지 않은 페이지를 교체하는 알고리즘이다.

### 스래싱과 프레임 할당

페이지 폴트가 자주 발생하는 이유는 나쁜 페이지 교체 알고리즘만 있는게 아니라 프로세스가 사용할 수 있는 프레임 수가 적어도 발생한다. 반대로 프로세스가 사용할 수 있는 프레임 수가 많으면 일반적으로 페이지 폴트 빈도는 감소한다.

프로세스가 실제 실행되는 시간보다 페이징에 더 많은 시간을 소요하여 성능이 저해되는 문제를 `스래싱`이라고 한다. 메모리에서 동시 실행되는 프로세스의 수를 멀티프로그래밍의 정도라고 한다. 이 정도가 높다면 현재 메모리에는 많은 프로세스가 실행 중이고, 낮다면 현재 메모리에는 적은 프로세스가 동시에 실행 중이다.

스래싱이 발생하는 가장 근본적인 원인은 각 프로세스가 필요로 하는 최소한의 프레임 수가 보장되지 않았기 때문이다.

모든 프로세스에 균등하게 프레임을 제공하는 방식을 `균등할당`, 프로세스 크기에 따라 프레임을 배분하는 방식을 `비례할당` 이라고 한다. 균등 할당과 비례 할당 방식은 프로세스의 실행 과정을 고려하지 않고 단순히 프로세스의 크기와 물리 메모리의 크기만을 고려한 방식이라는 점에서 정적 할당 방식이라고도 한다.

프로세스를 실행하는 과정에서 배분할 프레임을 결정하는 방식에는 크게 작업 집합 모델을 사용하는 방식과 페이지 폴트 빈도를 사용하는 방식이 있다. 이 두 개 방식은 프로세스의 실행을 보고 할당할 프레임 수를 결정한다는 점에서 동적 할당 방식이라고도 한다.

`작업 집합 모델 기반 프레임 할당`은 작업 집합의 크기만큼만 프레임을 할당하는 방식이다. 실행 중인 프로세스가 일정 시간 동안 참조한 페이지의 집합을 작업 집합이라고 한다. 작업 집합을 구하려면 프로세스가 참조한 페이지, 일정 시간 간격이 필요하다.

`페이지 폴트율 기반 프레임 할당` 은 페이지 폴트율에 상한선과 하한선을 정하고, 그 내부 범위 안에서만 프레임을 할당하는 방식이다.
